{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0e0247-f09a-4254-a546-3009c8736f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv.imread('tir/00002.jpg', cv.IMREAD_GRAYSCALE)  # referenceImage\n",
    "img2 = cv.imread('rgb/00002.jpg', cv.IMREAD_GRAYSCALE)  # sensedImage\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift_detector = cv.SIFT_create()\n",
    "# Find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift_detector.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift_detector.detectAndCompute(img2, None)\n",
    "\n",
    "# BFMatcher with default params\n",
    "bf = cv.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Filter out poor matches\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "matches = good_matches\n",
    "\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = kp1[match.queryIdx].pt\n",
    "    points2[i, :] = kp2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "H, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "# Warp image 1 to align with image 2\n",
    "img1Reg = cv2.warpPerspective(img1, H, (img2.shape[1], img2.shape[0]))\n",
    "cv.imwrite('aligned_img1.jpg', img1Reg)\n",
    "# The problem is that this matrix H is found via a compute-intensive optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129674e7-bf31-4a00-ba21-f3aa703a27f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08acd2-3db3-4426-b827-2d6b47724359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df445-65ee-48e7-bf9b-349bac69cdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64c79b-a327-417f-8dc4-da3caf8c7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv.imread('image1.jpg', cv.IMREAD_GRAYSCALE)  # referenceImage\n",
    "img2 = cv.imread('image2.jpg', cv.IMREAD_GRAYSCALE)  # sensedImage\n",
    "\n",
    "#  Resize the image by a factor of 8 on each side. If your images are \n",
    "# very high-resolution, you can try to resize even more, but if they are \n",
    "# already small you should set this to something less agressive.\n",
    "resize_factor = 1.0/8.0\n",
    "\n",
    "img1_rs = cv.resize(img1, (0,0), fx=resize_factor, fy=resize_factor)\n",
    "img2_rs = cv.resize(img2, (0,0), fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "# Initiate SIFT detector \n",
    "sift_detector = cv.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT on the lower resolution images\n",
    "kp1, des1 = sift_detector.detectAndCompute(img1_rs, None)\n",
    "kp2, des2 = sift_detector.detectAndCompute(img2_rs, None)\n",
    "\n",
    "# BFMatcher with default params\n",
    "bf = cv.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Filter out poor matches\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "matches = good_matches\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = kp1[match.queryIdx].pt\n",
    "    points2[i, :] = kp2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "H, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "# Get low-res and high-res sizes\n",
    "low_height, low_width = img1_rs.shape\n",
    "height, width = img1.shape\n",
    "low_size = np.float32([[0, 0], [0, low_height], [low_width, low_height], [low_width, 0]])\n",
    "high_size = np.float32([[0, 0], [0, height], [width, height], [width, 0]])\n",
    "\n",
    "# Compute scaling transformations\n",
    "scale_up = cv.getPerspectiveTransform(low_size, high_size)\n",
    "scale_down = cv.getPerspectiveTransform(high_size, low_size)\n",
    "\n",
    "#  Combine the transformations. Remember that the order of the transformation \n",
    "# is reversed when doing matrix multiplication\n",
    "# so this is actualy scale_down -> H -> scale_up\n",
    "h_and_scale_up = np.matmul(scale_up, H)\n",
    "scale_down_h_scale_up = np.matmul(h_and_scale_up, scale_down)\n",
    "\n",
    "# Warp image 1 to align with image 2\n",
    "img1Reg = cv2.warpPerspective(\n",
    "            img1, \n",
    "            scale_down_h_scale_up, \n",
    "            (img2.shape[1], img2.shape[0])\n",
    "          )\n",
    "\n",
    "cv.imwrite('aligned_img1.jpg', img1Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7252c6-1e71-44b3-b0f2-1e2c7fa7c393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedbfd6-8b18-4555-9409-c1195da3b172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc3860e-6896-44fa-9aed-c7732cfcca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def enhance_contrast(img):\n",
    "    # 对图像进行对比度增强\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced_img = clahe.apply(img)\n",
    "    return enhanced_img\n",
    "\n",
    "def double_light_fusion(visible_img, infrared_img):\n",
    "    # 可见光图像对比度增强\n",
    "    visible_enhanced = enhance_contrast(visible_img)\n",
    "    \n",
    "    # 红外图像对比度增强\n",
    "    infrared_enhanced = enhance_contrast(infrared_img)\n",
    "    \n",
    "    # 将对比度增强后的两个图像进行融合\n",
    "    fused_img = cv2.addWeighted(visible_enhanced, 0.5, infrared_enhanced, 0.5, 0)\n",
    "    \n",
    "    return fused_img\n",
    "\n",
    "# 读取可见光图像和红外图像\n",
    "visible_img = cv2.imread('rgb/00030.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "infrared_img = cv2.imread('tir/00030.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 进行双光融合\n",
    "fused_image = double_light_fusion(visible_img, infrared_img)\n",
    "\n",
    "# 显示融合后的图像\n",
    "cv2.imshow('Fused Image', fused_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv.imwrite('fused_image.jpg', fused_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82520a43-3db1-440b-8987-ec2746a9908a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc7ef0b-b9c5-44b3-b96d-495c6ef5cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fundam.cpp:385: error: (-28:Unknown error code -28) The input arrays should have at least 4 corresponding point sets to calculate Homography in function 'cv::findHomography'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(dst_pts)\u001b[38;5;66;03m#只有白天的才能找到配准点\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 计算变换矩阵\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m M, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindHomography(src_pts, dst_pts, cv2\u001b[38;5;241m.\u001b[39mRANSAC, \u001b[38;5;241m5.0\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 对光学图像进行透视变换，使其与红外图像配准\u001b[39;00m\n\u001b[0;32m     35\u001b[0m registered_img_optical \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwarpPerspective(img_optical, M, (img_ir\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img_ir\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fundam.cpp:385: error: (-28:Unknown error code -28) The input arrays should have at least 4 corresponding point sets to calculate Homography in function 'cv::findHomography'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取两个输入图像\n",
    "img_optical = cv2.imread('rgb/00001.jpg', 0)  # 光学图像\n",
    "img_ir = cv2.imread('tir/00001.jpg', 0)            # 红外图像\n",
    "\n",
    "# 使用SIFT检测特征点并计算描述符\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints_optical, descriptors_optical = sift.detectAndCompute(img_optical, None)\n",
    "keypoints_ir, descriptors_ir = sift.detectAndCompute(img_ir, None)\n",
    "\n",
    "# 使用FLANN匹配器匹配特征点\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(descriptors_optical, descriptors_ir, k=2)\n",
    "\n",
    "# 去除错误匹配\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# 提取配准点坐标\n",
    "src_pts = np.float32([keypoints_optical[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints_ir[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "print(dst_pts)#只有白天的才能找到配准点\n",
    "\n",
    "# 计算变换矩阵\n",
    "M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "# 对光学图像进行透视变换，使其与红外图像配准\n",
    "registered_img_optical = cv2.warpPerspective(img_optical, M, (img_ir.shape[1], img_ir.shape[0]))\n",
    "\n",
    "# 融合图像\n",
    "blended_img = cv2.addWeighted(registered_img_optical, 0.5, img_ir, 0.5, 0)\n",
    "\n",
    "\n",
    "# 保存显示结果\n",
    "cv.imwrite('blended_img_01.jpg', blended_img)\n",
    "cv2.imshow('Blended Image', blended_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57cf8f5d-67d8-48db-9833-30b8f609dabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c15e92b-5fcd-4446-be8a-fb28331a74d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fundam.cpp:385: error: (-28:Unknown error code -28) The input arrays should have at least 4 corresponding point sets to calculate Homography in function 'cv::findHomography'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m dst_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([keypoints_ir[m\u001b[38;5;241m.\u001b[39mtrainIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m good_matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 计算变换矩阵\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m M, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindHomography(src_pts, dst_pts, cv2\u001b[38;5;241m.\u001b[39mRANSAC, \u001b[38;5;241m5.0\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 对光学图像进行透视变换，使其与红外图像配准\u001b[39;00m\n\u001b[0;32m     44\u001b[0m registered_img_optical \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwarpPerspective(img_optical, M, (img_ir\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img_ir\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fundam.cpp:385: error: (-28:Unknown error code -28) The input arrays should have at least 4 corresponding point sets to calculate Homography in function 'cv::findHomography'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取输入图像\n",
    "img_ir = cv2.imread('tir/00001.jpg', 0)  # 红外图像\n",
    "img_optical = cv2.imread('rgb/00001.jpg', 0)  # 光学图像\n",
    "\n",
    "# 使用SIFT检测特征点并计算描述符（仅用于红外图像）\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints_ir, descriptors_ir = sift.detectAndCompute(img_ir, None)\n",
    "\n",
    "keypoints_optical, descriptors_optical = sift.detectAndCompute(img_optical, None)\n",
    "\n",
    "# 使用FLANN匹配器匹配特征点\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# 如果光学图像的特征点数太少，则使用红外图像的特征点进行匹配\n",
    "if len(keypoints_optical) >= 10:\n",
    "    # keypoints_optical, descriptors_optical = sift.detectAndCompute(img_optical, None)\n",
    "    matches = flann.knnMatch(descriptors_optical, descriptors_ir, k=2)\n",
    "else:\n",
    "    matches = flann.knnMatch(descriptors_ir, descriptors_ir, k=2)\n",
    "\n",
    "# 去除错误匹配\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# 提取配准点坐标\n",
    "if len(keypoints_optical) >= 10:\n",
    "    src_pts = np.float32([keypoints_optical[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "else:\n",
    "    src_pts = np.float32([keypoints_ir[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints_ir[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# 计算变换矩阵\n",
    "M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "# 对光学图像进行透视变换，使其与红外图像配准\n",
    "registered_img_optical = cv2.warpPerspective(img_optical, M, (img_ir.shape[1], img_ir.shape[0]))\n",
    "\n",
    "# 融合图像\n",
    "blended_img = cv2.addWeighted(registered_img_optical, 0.5, img_ir, 0.5, 0)\n",
    "\n",
    "# 显示结果\n",
    "cv.imwrite('blended_img_01.jpg', blended_img)\n",
    "cv2.imshow('Blended Image', blended_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f191377b-ea69-435f-adcd-58818eb988dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取输入图像\n",
    "img_ir = cv2.imread('tir/00847.jpg', 0)  # 红外图像\n",
    "img_optical = cv2.imread('rgb/00847.jpg', 0)  # 光学图像\n",
    "\n",
    "# 使用SIFT检测特征点并计算描述符（红外图像）\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints_ir, descriptors_ir = sift.detectAndCompute(img_ir, None)\n",
    "\n",
    "# 使用FLANN匹配器匹配特征点\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# 使用红外图像的特征点进行匹配\n",
    "matches = flann.knnMatch(descriptors_ir, descriptors_ir, k=2)\n",
    "\n",
    "# 去除错误匹配\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# 提取配准点坐标\n",
    "src_pts = np.float32([keypoints_ir[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints_ir[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# 计算变换矩阵\n",
    "M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "# 对光学图像进行透视变换，使其与红外图像配准\n",
    "registered_img_optical = cv2.warpPerspective(img_optical, M, (img_ir.shape[1], img_ir.shape[0]))\n",
    "\n",
    "# 融合图像\n",
    "blended_img = cv2.addWeighted(registered_img_optical, 0.5, img_ir, 0.5, 0)\n",
    "\n",
    "# 显示结果\n",
    "cv.imwrite('blended_img_847.jpg', blended_img)\n",
    "cv2.imshow('Blended Image', blended_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c456d-337d-4263-acbf-be7d0b57003a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
